{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distributed\n",
    "\n",
    "As we covered at the beginning Dask has the ability to run work on mulitple machines using the distributed scheduler.\n",
    "\n",
    "Until now we have actually been using the distributed scheduler for our work, but just on a single machine.\n",
    "\n",
    "When we instantiate a `Client()` object with no arguments it will attempt to locate a Dask cluster. It will check your local Dask config and environment variables to see if connection information has been specified. If not it will create an instance of `LocalCluster` and use that.\n",
    "\n",
    "*Specifying connection information in config is useful for system administrators to provide access to their users. We do this in the [Dask Helm Chart for Kubernetes](https://github.com/dask/helm-chart/blob/master/dask/templates/dask-jupyter-deployment.yaml#L46-L48), the chart installs a multi-node Dask cluster and a Jupyter server on a Kubernetes cluster and Jupyter is preconfigured to discover the distributed cluster.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local Cluster\n",
    "\n",
    "Let's explore the `LocalCluster` object ourselves and see what it is doing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import LocalCluster, Client\n",
    "\n",
    "cluster = LocalCluster()\n",
    "cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a cluster object will create a Dask scheduler and a number of Dask workers. If no arguments are specified then it will autodetect the number of CPU cores your system has and the amount of memory and create workers to appropriately fill that.\n",
    "\n",
    "You can also specify these arguments yourself. Let's have a look at the docstring to see the options we have available.\n",
    "\n",
    "*These arguments can also be passed to `Client` and in the case where it creates a `LocalCluster` they will just be passed on down the line.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LocalCluster?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our cluster object has attributes and methods which we can use to access information about our cluster. For instance we can get the log output from the scheduler and all the workers with the `get_logs()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<details>\n",
       "<summary style='display:list-item'>Scheduler</summary>\n",
       "<pre><code>\n",
       "distributed.scheduler - INFO - Clear task state\n",
       "distributed.scheduler - INFO -   Scheduler at:     tcp://127.0.0.1:53816\n",
       "distributed.scheduler - INFO -   dashboard at:            127.0.0.1:8787\n",
       "distributed.scheduler - INFO - Register worker &lt;Worker &#x27;tcp://127.0.0.1:53823&#x27;, name: 0, memory: 0, processing: 0&gt;\n",
       "distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:53823\n",
       "distributed.scheduler - INFO - Register worker &lt;Worker &#x27;tcp://127.0.0.1:53824&#x27;, name: 2, memory: 0, processing: 0&gt;\n",
       "distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:53824\n",
       "distributed.scheduler - INFO - Register worker &lt;Worker &#x27;tcp://127.0.0.1:53829&#x27;, name: 1, memory: 0, processing: 0&gt;\n",
       "distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:53829\n",
       "distributed.scheduler - INFO - Register worker &lt;Worker &#x27;tcp://127.0.0.1:53831&#x27;, name: 3, memory: 0, processing: 0&gt;\n",
       "distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:53831\n",
       "</code></pre>\n",
       "</details>\n",
       "<details>\n",
       "<summary style='display:list-item'>tcp://127.0.0.1:53823</summary>\n",
       "<pre><code>\n",
       "distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:53823\n",
       "distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:53823\n",
       "distributed.worker - INFO -          dashboard at:            127.0.0.1:53825\n",
       "distributed.worker - INFO - Waiting to connect to:      tcp://127.0.0.1:53816\n",
       "distributed.worker - INFO - -------------------------------------------------\n",
       "distributed.worker - INFO -               Threads:                          3\n",
       "distributed.worker - INFO -                Memory:                    4.29 GB\n",
       "distributed.worker - INFO -       Local Directory: /Users/jtomlinson/Projects/dask/dask-video-tutorial-2020/dask-worker-space/worker-dv4i1bkv\n",
       "distributed.worker - INFO - -------------------------------------------------\n",
       "distributed.worker - INFO -         Registered to:      tcp://127.0.0.1:53816\n",
       "distributed.worker - INFO - -------------------------------------------------\n",
       "</code></pre>\n",
       "</details>\n",
       "<details>\n",
       "<summary style='display:list-item'>tcp://127.0.0.1:53824</summary>\n",
       "<pre><code>\n",
       "distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:53824\n",
       "distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:53824\n",
       "distributed.worker - INFO -          dashboard at:            127.0.0.1:53826\n",
       "distributed.worker - INFO - Waiting to connect to:      tcp://127.0.0.1:53816\n",
       "distributed.worker - INFO - -------------------------------------------------\n",
       "distributed.worker - INFO -               Threads:                          3\n",
       "distributed.worker - INFO -                Memory:                    4.29 GB\n",
       "distributed.worker - INFO -       Local Directory: /Users/jtomlinson/Projects/dask/dask-video-tutorial-2020/dask-worker-space/worker-ecetvgmj\n",
       "distributed.worker - INFO - -------------------------------------------------\n",
       "distributed.worker - INFO -         Registered to:      tcp://127.0.0.1:53816\n",
       "distributed.worker - INFO - -------------------------------------------------\n",
       "</code></pre>\n",
       "</details>\n",
       "<details>\n",
       "<summary style='display:list-item'>tcp://127.0.0.1:53829</summary>\n",
       "<pre><code>\n",
       "distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:53829\n",
       "distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:53829\n",
       "distributed.worker - INFO -          dashboard at:            127.0.0.1:53830\n",
       "distributed.worker - INFO - Waiting to connect to:      tcp://127.0.0.1:53816\n",
       "distributed.worker - INFO - -------------------------------------------------\n",
       "distributed.worker - INFO -               Threads:                          3\n",
       "distributed.worker - INFO -                Memory:                    4.29 GB\n",
       "distributed.worker - INFO -       Local Directory: /Users/jtomlinson/Projects/dask/dask-video-tutorial-2020/dask-worker-space/worker-pyzv1frq\n",
       "distributed.worker - INFO - -------------------------------------------------\n",
       "distributed.worker - INFO -         Registered to:      tcp://127.0.0.1:53816\n",
       "distributed.worker - INFO - -------------------------------------------------\n",
       "</code></pre>\n",
       "</details>\n",
       "<details>\n",
       "<summary style='display:list-item'>tcp://127.0.0.1:53831</summary>\n",
       "<pre><code>\n",
       "distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:53831\n",
       "distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:53831\n",
       "distributed.worker - INFO -          dashboard at:            127.0.0.1:53833\n",
       "distributed.worker - INFO - Waiting to connect to:      tcp://127.0.0.1:53816\n",
       "distributed.worker - INFO - -------------------------------------------------\n",
       "distributed.worker - INFO -               Threads:                          3\n",
       "distributed.worker - INFO -                Memory:                    4.29 GB\n",
       "distributed.worker - INFO -       Local Directory: /Users/jtomlinson/Projects/dask/dask-video-tutorial-2020/dask-worker-space/worker-b9h6gy6i\n",
       "distributed.worker - INFO - -------------------------------------------------\n",
       "distributed.worker - INFO -         Registered to:      tcp://127.0.0.1:53816\n",
       "distributed.worker - INFO - -------------------------------------------------\n",
       "</code></pre>\n",
       "</details>"
      ],
      "text/plain": [
       "{'Scheduler': \"distributed.scheduler - INFO - Clear task state\\ndistributed.scheduler - INFO -   Scheduler at:     tcp://127.0.0.1:53816\\ndistributed.scheduler - INFO -   dashboard at:            127.0.0.1:8787\\ndistributed.scheduler - INFO - Register worker <Worker 'tcp://127.0.0.1:53823', name: 0, memory: 0, processing: 0>\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:53823\\ndistributed.scheduler - INFO - Register worker <Worker 'tcp://127.0.0.1:53824', name: 2, memory: 0, processing: 0>\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:53824\\ndistributed.scheduler - INFO - Register worker <Worker 'tcp://127.0.0.1:53829', name: 1, memory: 0, processing: 0>\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:53829\\ndistributed.scheduler - INFO - Register worker <Worker 'tcp://127.0.0.1:53831', name: 3, memory: 0, processing: 0>\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:53831\",\n",
       " 'tcp://127.0.0.1:53823': 'distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:53823\\ndistributed.worker - INFO -          Listening to:      tcp://127.0.0.1:53823\\ndistributed.worker - INFO -          dashboard at:            127.0.0.1:53825\\ndistributed.worker - INFO - Waiting to connect to:      tcp://127.0.0.1:53816\\ndistributed.worker - INFO - -------------------------------------------------\\ndistributed.worker - INFO -               Threads:                          3\\ndistributed.worker - INFO -                Memory:                    4.29 GB\\ndistributed.worker - INFO -       Local Directory: /Users/jtomlinson/Projects/dask/dask-video-tutorial-2020/dask-worker-space/worker-dv4i1bkv\\ndistributed.worker - INFO - -------------------------------------------------\\ndistributed.worker - INFO -         Registered to:      tcp://127.0.0.1:53816\\ndistributed.worker - INFO - -------------------------------------------------',\n",
       " 'tcp://127.0.0.1:53824': 'distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:53824\\ndistributed.worker - INFO -          Listening to:      tcp://127.0.0.1:53824\\ndistributed.worker - INFO -          dashboard at:            127.0.0.1:53826\\ndistributed.worker - INFO - Waiting to connect to:      tcp://127.0.0.1:53816\\ndistributed.worker - INFO - -------------------------------------------------\\ndistributed.worker - INFO -               Threads:                          3\\ndistributed.worker - INFO -                Memory:                    4.29 GB\\ndistributed.worker - INFO -       Local Directory: /Users/jtomlinson/Projects/dask/dask-video-tutorial-2020/dask-worker-space/worker-ecetvgmj\\ndistributed.worker - INFO - -------------------------------------------------\\ndistributed.worker - INFO -         Registered to:      tcp://127.0.0.1:53816\\ndistributed.worker - INFO - -------------------------------------------------',\n",
       " 'tcp://127.0.0.1:53829': 'distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:53829\\ndistributed.worker - INFO -          Listening to:      tcp://127.0.0.1:53829\\ndistributed.worker - INFO -          dashboard at:            127.0.0.1:53830\\ndistributed.worker - INFO - Waiting to connect to:      tcp://127.0.0.1:53816\\ndistributed.worker - INFO - -------------------------------------------------\\ndistributed.worker - INFO -               Threads:                          3\\ndistributed.worker - INFO -                Memory:                    4.29 GB\\ndistributed.worker - INFO -       Local Directory: /Users/jtomlinson/Projects/dask/dask-video-tutorial-2020/dask-worker-space/worker-pyzv1frq\\ndistributed.worker - INFO - -------------------------------------------------\\ndistributed.worker - INFO -         Registered to:      tcp://127.0.0.1:53816\\ndistributed.worker - INFO - -------------------------------------------------',\n",
       " 'tcp://127.0.0.1:53831': 'distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:53831\\ndistributed.worker - INFO -          Listening to:      tcp://127.0.0.1:53831\\ndistributed.worker - INFO -          dashboard at:            127.0.0.1:53833\\ndistributed.worker - INFO - Waiting to connect to:      tcp://127.0.0.1:53816\\ndistributed.worker - INFO - -------------------------------------------------\\ndistributed.worker - INFO -               Threads:                          3\\ndistributed.worker - INFO -                Memory:                    4.29 GB\\ndistributed.worker - INFO -       Local Directory: /Users/jtomlinson/Projects/dask/dask-video-tutorial-2020/dask-worker-space/worker-b9h6gy6i\\ndistributed.worker - INFO - -------------------------------------------------\\ndistributed.worker - INFO -         Registered to:      tcp://127.0.0.1:53816\\ndistributed.worker - INFO - -------------------------------------------------'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster.get_logs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can access the url that the Dask dashboard is being hosted at."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'http://127.0.0.1:8787/status'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster.dashboard_link"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order for Dask to use our cluster we still need to create a `Client` object, but as we have already created a cluster we can pass that directly to our client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Client</h3>\n",
       "<ul style=\"text-align: left; list-style: none; margin: 0; padding: 0;\">\n",
       "  <li><b>Scheduler: </b>tcp://127.0.0.1:53816</li>\n",
       "  <li><b>Dashboard: </b><a href='http://127.0.0.1:8787/status' target='_blank'>http://127.0.0.1:8787/status</a></li>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Cluster</h3>\n",
       "<ul style=\"text-align: left; list-style:none; margin: 0; padding: 0;\">\n",
       "  <li><b>Workers: </b>4</li>\n",
       "  <li><b>Cores: </b>12</li>\n",
       "  <li><b>Memory: </b>17.18 GB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: 'tcp://127.0.0.1:53816' processes=4 threads=12, memory=17.18 GB>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client = Client(cluster)\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "del client, cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remote clusters via SSH\n",
    "\n",
    "A common way to distribute your work onto multiple machines is via SSH. Dask has a cluster manager which will handle creating SSH connections for you called `SSHCluster`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import SSHCluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When constructing this cluster manager we need to pass a list of addresses, either hostnames or IP addresses, which we will SSH into and attempt to start a Dask scheduler or worker on. As this tutorial is designed for Binder we will quickly setup the ability to SSH to `localhost`, which this isn't actually useful it should illustrate the point that you can SSH to other systems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:dask-tutorial]",
   "language": "python",
   "name": "conda-env-dask-tutorial-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
